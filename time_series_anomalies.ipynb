{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anomalies in Time Series Data\n",
    "\n",
    "**Lesson Goals**\n",
    "\n",
    "- Use entropy as a quick way to identify fields that may have anomalies. \n",
    "\n",
    "- Use statistical properties to flag the data points that deviate from the expected. \n",
    "\n",
    "**The Data**\n",
    "\n",
    "- Logs of API requests to our data containing sales information about our stores and items. \n",
    "\n",
    "- Type of target variable: **Continuous** or Discrete\n",
    "\n",
    "- Type of observations: **Time Series** or Point in Time   \n",
    "\n",
    "\n",
    "**The Questions**\n",
    "\n",
    "- Are there unusual IP addresses accessing our data via the API? \n",
    "\n",
    "- Have we seen any spikes or unusual patterns in the size of requests? \n",
    "\n",
    "- In general: Does this new value deviate from what we would expect based on historical data? If so, is it something to be concerned about? Remember, we aren't detecting anomalies for the sake of detecting anomalies. \n",
    "\n",
    "\n",
    "_____________________________\n",
    "\n",
    "\n",
    "## Wrangle Data\n",
    "\n",
    "**Prepare Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn import metrics\n",
    "\n",
    "from scipy.stats import entropy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates #to format dates on our plots\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# This is to make sure matplotlib doesn't throw the following error:\n",
    "# The next line fixes \"TypeError: float() argument must be a string or a number, not 'Timestamp' matplotlib\"\n",
    "pd.plotting.register_matplotlib_converters()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Acquire**\n",
    "\n",
    "After doing some research, some experimentation of performing actions and watching the logs, we discovered what each of the fields represent. We then parse and name the fields accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=['ip', 'timestamp', 'request_method', 'status', 'size',\n",
    "          'destination', 'request_agent']\n",
    "df = pd.read_csv('https://python.zach.lol/access.log',          \n",
    "                 engine='python',\n",
    "                 header=None,\n",
    "                 index_col=False,\n",
    "                 names=colnames,\n",
    "                 sep=r'\\s(?=(?:[^\"]*\"[^\"]*\")*[^\"]*$)(?![^\\[]*\\])',\n",
    "                 na_values='\"-\"',\n",
    "                 usecols=[0, 3, 4, 5, 6, 7, 8]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this research, we are only interested in the IP address, timestamp and size of the requests. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['ip', 'timestamp', 'size']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Explore IP Address**\n",
    "\n",
    "In this sample data, it's pretty easy to take a look at value counts to see those IP's that are rare. However, usually the data is much, much larger and looking at simple value counts is not going to be enough. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# value counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_entropy(series):\n",
    "    counts = series.value_counts()\n",
    "    if len(counts)==1:\n",
    "        ent = 0\n",
    "    else:\n",
    "        value, counts = np.unique(series, return_counts=True)\n",
    "        ent = entropy(counts, base=None)\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(df.ip.value_counts())\n",
    "\n",
    "# value, counts = np.unique(df.ip, return_counts=True)\n",
    "# ent = entropy(counts, base=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_entropy(df.ip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prepare Data to Explore Size**\n",
    "\n",
    "First, we will resample the existing data to 30 minute increments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select timestamp\n",
    "df.timestamp = df.timestamp.str.replace(r'(\\[|\\])', '', regex=True)\n",
    "df.timestamp = pd.to_datetime(df.timestamp.str.replace(':', ' ', 1))\n",
    "df = df.set_index('timestamp')\n",
    "df = df[['size']].resample('1d').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna(value=0)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Aside: Simulate some new data to manufacture some anomalies**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's create a new dataframe that extends our data another year or so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = pd.DataFrame([[\"[18/Apr/2019:00:00:00+0000]\", 0],\n",
    "                    [\"[15/Mar/2020:00:00:00+0000]\", 0]], columns=['timestamp','size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will then resample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.timestamp = new.timestamp.str.replace(r'(\\[|\\])', '', regex=True)\n",
    "new.timestamp = pd.to_datetime(new.timestamp.str.replace(':', ' ', 1))\n",
    "new = new.set_index('timestamp')\n",
    "new = new.resample('1d').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new = new.fillna(value=0)\n",
    "new.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mean and standard deviation for randomly generating some data. \n",
    "mean = df['size'].mean()\n",
    "std = df['size'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill values with random number between `[0, mean+2*standard deviation]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new['size'] = new['size'].apply(lambda x: max(np.rint(np.random.normal(mean, std)), 0) if x==0 else x)\n",
    "new['size'] = new['size'].apply(lambda x: np.random.randint(0, mean+2*std) if x==0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill with some anomalies by replacing the zeros that remain with random number between `[(mean+2*std), (mean+5*std)]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['size'] = new['size'].apply(lambda x: np.random.randint(mean+5*std, mean+9*std) if x<200000000 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatentate our new data with our original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, new])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(df['size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's represent size in MB for ease of conceptual understanding.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['size_mb'] = [n/1024/1024 for n in df['size']]\n",
    "df = df[['size_mb']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split into Train/Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:'2019-10-17']\n",
    "validate = df['2019-10-18':'2020-01-15']\n",
    "test = df['2020-01-16':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "plt.plot(train)\n",
    "plt.plot(validate)\n",
    "plt.plot(test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Moving Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 week\n",
    "sma_short = train.rolling(window=7).mean()\n",
    "sma_short[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sma_long = train.rolling(window=30).mean()\n",
    "sma_long[27:33]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Plot the SMA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "\n",
    "ax.plot(train.index, train, label='Size (MB)')\n",
    "\n",
    "ax.plot(train.index, sma_short, label = '7-day SMA')\n",
    "\n",
    "ax.plot(train.index, sma_long, label = '30-day SMA')\n",
    "\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel('Size (MB)')\n",
    "# ax.xaxis.(rotate=90)\n",
    "# ax.xaxis.set_major_formatter(my_datetime_fmt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try some other windows to compare. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exponential Moving Average\n",
    "\n",
    "SMA time series are much less noisy than the time series of the original data points. \n",
    "The challenge with SMA, however, is that the values of SMA lag the original values. This means that changes in the trend are only seen with a delay (lag) of L time units. \n",
    "\n",
    "Exponential Moving Average (EMA) helps reduce the lag induced by the use of the SMA. It does this by putting more weight on more recent observations, while the SMA weights all observations equally.\n",
    "\n",
    "The EMA function looks like this: \n",
    "\n",
    "$EMA_{t}= \\alpha * (t_{0} - EMA_{t-1}) + EMA_{t-1}$\n",
    "\n",
    "Where: \n",
    "\n",
    "- M = Number of time periods, span of the window\n",
    "\n",
    "- $t_{0}$ = Latest value\n",
    "\n",
    "- $t-1$ = Previous value\n",
    "\n",
    "- $EMA_{t-1}$ = Exponential moving average of previous day. \n",
    "\n",
    "- The multiplier: $\\alpha = \\frac{2}{M+1}$\n",
    "\n",
    "However, we will use the pandas ewm (Exponential Weighted functions) to compute our EMA. \n",
    "So we just need to define the following: \n",
    "\n",
    "- M = `span` argument = number of time periods. We will use 1 week, which is $24*2*7 = 336$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_short = train.ewm(span=7).mean()\n",
    "ema_short.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_long = train.ewm(span=30).mean()\n",
    "ema_long.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comparison of SMA and EMA**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "ax.plot(train.index, train, label='Size (MB)', alpha=.5)\n",
    "\n",
    "ax.plot(train.index, sma_short, label = '7-day SMA')\n",
    "ax.plot(train.index, ema_short, label = '7-day EMA')\n",
    "\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel('Size (MB)')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,6))\n",
    "\n",
    "ax.plot(train.index, train, label='Size (MB)', alpha=.5)\n",
    "\n",
    "ax.plot(train.index, sma_long, label = '30-day SMA')\n",
    "ax.plot(train.index, ema_long, label = '30-day EMA')\n",
    "\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel('Size (MB)')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# ax.xaxis.(rotate=90)\n",
    "# ax.xaxis.set_major_formatter(my_datetime_fmt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bollinger Bands and %b\n",
    "\n",
    "**Bollinger Bands**\n",
    "\n",
    "- a volatility indicator and commonly used in stock market trading. \n",
    "\n",
    "- Made up of 3 lines, the Upper Band (UB), the Lower Band (LB) and the Midband.  \n",
    "\n",
    "**Midband**\n",
    "\n",
    "- The Exponential Moving Average\n",
    "\n",
    "- `midband = train.ewm(span=336).mean()`\n",
    "\n",
    "**Upper & Lower Band**\n",
    "\n",
    "- UB/LB = Midband +/- stdev * K\n",
    "\n",
    "- `stdev = train.ewm(span=336).std()` \n",
    "\n",
    "- K = the number of standard deviations to go up and down from the EMA\n",
    "\n",
    "**%b, Percent Bandwidth**\n",
    "\n",
    "- Shows where the last value sits in relation to the bands\n",
    "\n",
    "- $\\%b = \\frac{last-LB}{UB-LB}$ \n",
    "\n",
    "- %b > 1 => point lies above UB\n",
    "\n",
    "- %b < 0 => point lies below LB\n",
    "\n",
    "- %b == .5 => point lies on the midband. \n",
    "\n",
    "**Bandwidth** \n",
    "\n",
    "- The width of the bands\n",
    "\n",
    "- $Bandwidth = \\frac{(UB-LB)}{Midband}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the window span\n",
    "span = 30\n",
    "\n",
    "# compute midband\n",
    "midband = train.ewm(span=span).mean()\n",
    "\n",
    "# compute exponential stdev\n",
    "stdev = train.ewm(span=span).std()\n",
    "\n",
    "# compute upper and lower bands\n",
    "ub = midband + stdev*3\n",
    "lb = midband - stdev*3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the bands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12,8))\n",
    "\n",
    "ax.plot(train.index, \n",
    "        train,\n",
    "        label='Size (MB)')\n",
    "\n",
    "ax.plot(train.index, \n",
    "        midband, \n",
    "        label = '1-week EMA/midband')\n",
    "ax.plot(train.index, \n",
    "        ub, \n",
    "        label = 'Upper Band')\n",
    "ax.plot(train.index, \n",
    "        lb, \n",
    "        label = 'Lower Band')\n",
    "\n",
    "ax.legend(loc='best')\n",
    "ax.set_ylabel('Size (MB)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where do you think we will have a %b > 1? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute %b\n",
    "\n",
    "$\\%b = \\frac{last-LB}{UB-LB}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.concat([train, midband, ub, lb], axis=1)\n",
    "train.columns = ['size_mb', 'midband', 'ub', 'lb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['pct_b'] = (train['size_mb'] - train['lb'])/(train['ub'] - train['lb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[train['pct_b']>.9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "**file name:** time_series_anomaly_detection.py or time_series_anomaly_detection.ipynb\n",
    "\n",
    "Discover users who are accessing our curriculum pages way beyond the end of their codeup time. What would the dataframe look like? Use time series method for detecting anomalies, like exponential moving average with %b.\n",
    "\n",
    "Bonus:\n",
    "\n",
    "Can you label students who are viewing both the web dev and data science curriculum?\n",
    "Can you label students by the program they are in? \n",
    "Can you label users by student vs. staff?\n",
    "What are Zach, Maggie, Faith, and Ryan's ids?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to fabricate some anomalous observations for demonstration purposes as we work through the lesson. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
